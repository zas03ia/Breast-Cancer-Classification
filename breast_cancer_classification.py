# -*- coding: utf-8 -*-
"""Breast Cancer Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jq-sbSSMPNoPB1lsg06Pj2d9b_JzuYyk
"""

import numpy as np
import pandas as pd
import sklearn.datasets
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

data_frame = pd.read_csv("data.csv")

print(dataset)

data_frame.keys()

data_frame.shape

data_frame.isnull().sum()

data_frame = data_frame.drop(['Unnamed: 32'],axis = 1)
data_frame = data_frame.dropna(axis = 0, subset = ['fractal_dimension_worst','radius_worst','fractal_dimension_se','concavity_se','compactness_se','fractal_dimension_mean','compactness_mean','radius_mean'])
data_frame.shape

data_frame.head()

data_frame['label'] = dataset.target
data_frame.shape

data_frame.info()

data_frame.tail()

data_frame.isnull().sum()

data_frame['label'].value_counts()

"""0 --- Benign

1 --- Malignant

"""

data_frame.groupby('label').mean()

x_data_frame = data_frame.drop(columns = 'label', axis = 1)
y_data_frame = data_frame['label']

print(x_data_frame)

print(y_data_frame)

import seaborn as sns
import matplotlib.pyplot as plt

sns.countplot(x = data_frame['label'], label = 'count')
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

sns.set(style="darkgrid")

ax = sns.countplot(x=data_frame['label'])

ax.set_xticklabels(['Benign', 'Malignant'])

ax.set(xlabel='Label', ylabel='Count')

plt.show()

from sklearn.preprocessing import LabelEncoder
labelencoder_label = LabelEncoder()

data_frame.iloc[:,1] = labelencoder_label.fit_transform(data_frame.iloc[:,1].values)

data_frame.iloc[:,1].values

sns.pairplot(data_frame.iloc[:,1:10], hue = 'diagnosis')
plt.show()

data_frame.iloc[:,1:25].corr()

plt.figure(figsize= (15,10))
sns.heatmap(data_frame.iloc[:,1:25].corr(),cmap = "YlGnBu",annot = False, fmt = '.0%')

data_frame = data_frame.drop(['perimeter_mean'],axis = 1)

plt.figure(figsize= (15,10))
sns.heatmap(data_frame.iloc[:,1:25].corr(),cmap = "YlGnBu",annot = True, fmt = '.0%')

x_data_frame = data_frame.iloc[:,2:31].values
y_data_frame = data_frame.iloc[:,1].values

from sklearn.model_selection import train_test_split
x_train, x_test , y_train , y_test = train_test_split(x_data_frame, y_data_frame, test_size = 0.30, stratify= y_data_frame, random_state = 0)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

x_train = scaler.fit_transform(x_train)

x_test = scaler.transform(x_test)

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB

#Logistic Regression

def logistic_model(x_train, y_train):
  log = LogisticRegression(random_state=0)
  log.fit(x_train, y_train)
  return log

#Decision Tree

def decision_tree_model(x_train, y_train):
  tree = DecisionTreeClassifier(random_state=0)
  tree.fit(x_train, y_train)
  return tree

#Random Forest

def random_forest_model(x_train, y_train):
  forest = RandomForestClassifier(random_state=0)
  forest.fit(x_train, y_train)
  return forest

# Naive Bayes

def naive_bayes(x_train, y_train):
  nb = GaussianNB()
  nb.fit(x_train, y_train)
  return nb

# SVM (linear)

def svm(x_train, y_train):
  svc = SVC(kernel = 'linear', random_state = 0)
  svc.fit(x_train, y_train)
  return svc


logistic_model = logistic_model(x_train, y_train)
decision_tree_model = decision_tree_model(x_train, y_train)
random_forest_model = random_forest_model(x_train, y_train)
svc_model = svm(x_train, y_train)
naive_bayes_model = naive_bayes(x_train, y_train)



logistic_accuracy = logistic_model.score(x_test, y_test)
decision_tree_accuracy = decision_tree_model.score(x_test, y_test)
random_forest_accuracy = random_forest_model.score(x_test, y_test)
svc_accuracy = svc_model.score(x_test, y_test)
naive_bayes_accuracy = naive_bayes_model.score(x_test, y_test)


print("The accuracy of Logistic Regression ", logistic_accuracy)
print("The accuracy of Decision Tree ", decision_tree_accuracy)
print("The accuracy of Random Forest Classifier ",random_forest_accuracy)
print("The accuracy of Linear Support Vector Machine ",svc_accuracy)
print("The accuracy of Naive Bayes Algorithm ",naive_bayes_accuracy)

from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

#logistic regression confusion matrix

logistic_cm = confusion_matrix(y_test, logistic_model.predict(x_test))

logistic_tp = logistic_cm[0][0]

logistic_tn = logistic_cm[1][1]

logistic_fn =  logistic_cm[1][0]

logistic_fp = logistic_cm[0][1]

logistic_accuracy = (logistic_tp+ logistic_tn)/ (logistic_tp+ logistic_tn + logistic_fp + logistic_fn)

print("Logistic Regression Confusion Matrix:")

print(logistic_cm)

print("Logistic Regression Accuracy:", logistic_accuracy)

sns.heatmap(logistic_cm,
            annot=True,
            fmt='g',
            xticklabels=['malignant', 'benign'],
            yticklabels=['malignant', 'benign'])
plt.ylabel('Prediction',fontsize=13)
plt.xlabel('Actual',fontsize=13)
plt.title('Confusion Matrix',fontsize=17)
plt.show()


# Finding precision and recall
accuracy = accuracy_score(y_test, logistic_model.predict(x_test))
print("Accuracy   :", accuracy)
precision = precision_score(y_test, logistic_model.predict(x_test))
print("Precision :", precision)
recall = recall_score(y_test, logistic_model.predict(x_test))
print("Recall    :", recall)
F1_score = f1_score(y_test, logistic_model.predict(x_test))
print("F1-score  :", F1_score)

#Decision tree confusion matrix
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

decision_tree_cm =  confusion_matrix(y_test, decision_tree_model.predict(x_test))


decision_tree_tp =  decision_tree_cm[0][0]

decision_tree_tn  = decision_tree_cm[1][1]

decision_tree_fn = decision_tree_cm[1][0]

decision_tree_fp = decision_tree_cm[0][1]

decision_tree_accuracy = (decision_tree_tp + decision_tree_tn) / (decision_tree_tp + decision_tree_tn + decision_tree_fp + decision_tree_fn)

print("Decision Tree Confusion Matrix:")

print (decision_tree_cm)

print("Decision Tree Accuracy:",decision_tree_accuracy)

sns.heatmap(decision_tree_cm,
            annot=True,
            fmt='g',
            xticklabels=['malignant', 'benign'],
            yticklabels=['malignant', 'benign'])
plt.ylabel('Prediction',fontsize=13)
plt.xlabel('Actual',fontsize=13)
plt.title('Confusion Matrix',fontsize=17)
plt.show()


# Finding precision and recall
accuracy = accuracy_score(y_test, decision_tree_model.predict(x_test))
print("Accuracy   :", accuracy)
precision = precision_score(y_test, decision_tree_model.predict(x_test))
print("Precision :", precision)
recall = recall_score(y_test, decision_tree_model.predict(x_test))
print("Recall    :", recall)
F1_score = f1_score(y_test, decision_tree_model.predict(x_test))
print("F1-score  :", F1_score)

# random forests confusion matrix

random_forest_cm = confusion_matrix(y_test, random_forest_model.predict(x_test))

random_forest_tp = random_forest_cm[0][0]

random_forest_tn = random_forest_cm[1][1]

random_forest_fn = random_forest_cm[1][0 ]

random_forest_fp = random_forest_cm[0][1]

random_forest_accuracy = (random_forest_tp + random_forest_tn) / (random_forest_tp + random_forest_tn + random_forest_fp + random_forest_fn)


print("Random Forest Confusion Matrix:")

print(random_forest_cm)

print("Random Forest Accuracy:", random_forest_accuracy)
sns.heatmap(random_forest_cm,
            annot=True,
            fmt='g',
            xticklabels=['malignant', 'benign'],
            yticklabels=['malignant', 'benign'])
plt.ylabel('Prediction',fontsize=13)
plt.xlabel('Actual',fontsize=13)
plt.title('Confusion Matrix',fontsize=17)
plt.show()


# Finding precision and recall
accuracy = accuracy_score(y_test, random_forest_model.predict(x_test))
print("Accuracy   :", accuracy)
precision = precision_score(y_test, random_forest_model.predict(x_test))
print("Precision :", precision)
recall = recall_score(y_test, random_forest_model.predict(x_test))
print("Recall    :", recall)
F1_score = f1_score(y_test, random_forest_model.predict(x_test))
print("F1-score  :", F1_score)

from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

#logistic regression confusion matrix

naive_bayes_cm = confusion_matrix(y_test, naive_bayes_model.predict(x_test))

naive_bayes_tp = naive_bayes_cm[0][0]

naive_bayes_tn = naive_bayes_cm[1][1]

naive_bayes_fn =  naive_bayes_cm[1][0]

naive_bayes_fp = naive_bayes_cm[0][1]

naive_bayes_accuracy = (naive_bayes_tp+ naive_bayes_tn)/ (naive_bayes_tp+ naive_bayes_tn + naive_bayes_fp + naive_bayes_fn)

print("Naive Bayes Confusion Matrix:")

print(naive_bayes_cm)

print("Naive Bayes Accuracy:", naive_bayes_accuracy)

sns.heatmap(naive_bayes_cm,
            annot=True,
            fmt='g',
            xticklabels=['malignant', 'benign'],
            yticklabels=['malignant', 'benign'])
plt.ylabel('Prediction',fontsize=13)
plt.xlabel('Actual',fontsize=13)
plt.title('Confusion Matrix',fontsize=17)
plt.show()


# Finding precision and recall
accuracy = accuracy_score(y_test, naive_bayes_model.predict(x_test))
print("Accuracy   :", accuracy)
precision = precision_score(y_test, naive_bayes_model.predict(x_test))
print("Precision :", precision)
recall = recall_score(y_test, naive_bayes_model.predict(x_test))
print("Recall    :", recall)
F1_score = f1_score(y_test, naive_bayes_model.predict(x_test))
print("F1-score  :", F1_score)

from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

#logistic regression confusion matrix

svc_cm = confusion_matrix(y_test, svc_model.predict(x_test))

svc_tp = svc_cm[0][0]

svc_tn = svc_cm[1][1]

svc_fn =  svc_cm[1][0]

svc_fp = svc_cm[0][1]

svc_accuracy = (svc_tp+ svc_tn)/ (svc_tp+ svc_tn + svc_fp + svc_fn)

print("SVC Confusion Matrix:")

print(svc_cm)

print("SVC Accuracy:", svc_accuracy)

sns.heatmap(svc_cm,
            annot=True,
            fmt='g',
            xticklabels=['malignant', 'benign'],
            yticklabels=['malignant', 'benign'])
plt.ylabel('Prediction',fontsize=13)
plt.xlabel('Actual',fontsize=13)
plt.title('Confusion Matrix',fontsize=17)
plt.show()


# Finding precision and recall
accuracy = accuracy_score(y_test, svc_model.predict(x_test))
print("Accuracy   :", accuracy)
precision = precision_score(y_test, svc_model.predict(x_test))
print("Precision :", precision)
recall = recall_score(y_test, svc_model.predict(x_test))
print("Recall    :", recall)
F1_score = f1_score(y_test, svc_model.predict(x_test))
print("F1-score  :", F1_score)

from sklearn.metrics import classification_report, accuracy_score

models = [logistic_model, decision_tree_model, random_forest_model,naive_bayes_model,svc_model]

for i, model in enumerate(models):

  print("Model: ",  model)

  y_pred = model.predict(x_test)

  print(classification_report(y_test, y_pred))

  print('Accuracy:', accuracy_score(y_test, y_pred))

  print()

#Bar graph


import matplotlib.pyplot as plt


model_names = ['logistic', 'decsn_tree', 'rdm_forest', 'svc', 'naive_bayes']
accuracies = [logistic_accuracy, decision_tree_accuracy, random_forest_accuracy, svc_accuracy, naive_bayes_accuracy]

# Create a bar plot
plt.bar(model_names, accuracies)

for i, accuracy in enumerate(accuracies):
    plt.text(i, accuracy + 0.01, f'{accuracy:.2f}', ha='center', va='bottom', color='black')

# Add labels and title
plt.xlabel('Model')
plt.ylabel('Accuracy')
plt.title('Accuracy of Different ML Models')


plt.show()